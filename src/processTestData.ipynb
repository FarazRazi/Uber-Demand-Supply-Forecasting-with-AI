{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to clean and pre-process the data\n",
    "# import data using pandas\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_map finished\n",
      "cluster_map.head(): \n",
      "                         region_hash  region_id\n",
      "0  90c5a34f06ac86aee0fd70e2adce7d8a          1\n",
      "1  f2c8c4bb99e6377d21de71275afd6cd2          2\n",
      "2  58c7a4888306d8ff3a641d1c0feccbe3          3\n",
      "3  b26a240205c852804ff8758628c0a86a          4\n",
      "4  4b9e4cf2fbdc8281b8a1f9f12b80ce4d          5\n"
     ]
    }
   ],
   "source": [
    "# label the cluster map\n",
    "# labels:\n",
    "# region_hash, region_id\n",
    "\n",
    "columns = ['region_hash', 'region_id']\n",
    "# read the cluster map\n",
    "cluster_map = pd.read_csv('../dataset/test_set/cluster_map/cluster_map', sep='\\t', on_bad_lines='skip', header=None, names=columns)\n",
    "print('cluster_map finished')\n",
    "\n",
    "print('cluster_map.head(): \\n', cluster_map.head())\n",
    "\n",
    "\n",
    "cluster_map.to_csv('../dataset/labeledTestSet/cluster_map.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  ../dataset/test_set/order_data\\test_order_data_2016-01-23\n",
      "filename:  ../dataset/test_set/order_data\\test_order_data_2016-01-25\n",
      "filename:  ../dataset/test_set/order_data\\test_order_data_2016-01-27\n",
      "filename:  ../dataset/test_set/order_data\\test_order_data_2016-01-29\n",
      "filename:  ../dataset/test_set/order_data\\test_order_data_2016-01-31\n",
      "orders_data finished\n"
     ]
    }
   ],
   "source": [
    "# label the orders data\n",
    "# labels:\n",
    "# order_id, driver_id, passenger_id, start_district_hash, dest_district_hash, price, time\n",
    "\n",
    "columns = ['order_id', 'driver_id', 'start_region_hash', 'dest_region_hash', 'time']\n",
    "\n",
    "# read the orders data\n",
    "orders_data = []\n",
    "for f in glob.glob('../dataset/test_set/order_data/test_order_data_*'):\n",
    "    # file name\n",
    "    print('filename: ', f)\n",
    "    df = pd.read_csv(f, sep=',', on_bad_lines='skip', header=None, names=columns)\n",
    "    orders_data.append(df)\n",
    "\n",
    "print('orders_data finished')\n",
    "orders_data = pd.concat(orders_data,  ignore_index=True)\n",
    "\n",
    "# print('orders_data.head(): ', orders_data.head())\n",
    "orders_data.to_csv('../dataset/labeledTestSet/orders_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  ../dataset/test_set/weather_data\\weather_data_2016-01-23_test\n",
      "filename:  ../dataset/test_set/weather_data\\weather_data_2016-01-25_test\n",
      "filename:  ../dataset/test_set/weather_data\\weather_data_2016-01-27_test\n",
      "filename:  ../dataset/test_set/weather_data\\weather_data_2016-01-29_test\n",
      "filename:  ../dataset/test_set/weather_data\\weather_data_2016-01-31_test\n",
      "weather_data finished\n"
     ]
    }
   ],
   "source": [
    "# label the weather data\n",
    "# labels:\n",
    "# time, weather, temperature, pm25\n",
    "columns = ['time', 'weather', 'temperature', 'pm25']\n",
    "\n",
    "# print('weather_data.head(): \\n', weather_data.head())\n",
    "\n",
    "\n",
    "# # read the weather data\n",
    "weather_data = []\n",
    "for f in glob.glob('../dataset/test_set/weather_data/weather_data_*'):\n",
    "    # file name\n",
    "    print('filename: ', f)\n",
    "    df = pd.read_csv(f, sep='\\t', on_bad_lines='skip', header=None, names=columns)\n",
    "    weather_data.append(df)\n",
    "\n",
    "print('weather_data finished')\n",
    "weather_data = pd.concat(weather_data, ignore_index=True)\n",
    "\n",
    "\n",
    "weather_data.to_csv('../dataset/labeledTestSet/weather_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_poi_data.head():                          region_hash    poi_ids\n",
      "0  74c1c25f4b283fa74a5514307b0d0278  192205092\n",
      "1  08f5b445ec6b29deba62e6fd8b0325a6   11664654\n",
      "2  4b7f6f4e2bf237b6cc58f57142bea5c0   26846101\n",
      "3  a814069db8d32f0fa6e188f41059c6e1   21808997\n",
      "4  8316146a6f78cc6d9f113f0390859417    6828078\n"
     ]
    }
   ],
   "source": [
    "# label the poi data\n",
    "# labels:\n",
    "# region_hash, poi_id \n",
    "# 1st column: district_hash\n",
    "# whole next column is: poi_id\n",
    "columns = ['region_hash', 'poi_id']\n",
    "\n",
    "\n",
    "\n",
    "# read the poi data\n",
    "poi_data = pd.read_csv('../dataset/test_set/poi_data/poi_data', sep='\\t', header=None, on_bad_lines='skip')\n",
    "\n",
    "# extract the district_hash column and the POI ID columns\n",
    "district_hash = poi_data.iloc[:, 0]\n",
    "poi_ids = poi_data.iloc[:, 1:]\n",
    "\n",
    "# combine all the POI IDs for each row into a list\n",
    "poi_ids_list = poi_ids.apply(lambda x: x.tolist(), axis=1)\n",
    "\n",
    "# combine the district_hash and poi_ids_list into a new DataFrame\n",
    "labeled_poi_data = pd.concat([district_hash, poi_ids_list], axis=1)\n",
    "labeled_poi_data.columns = ['region_hash', 'poi_ids']\n",
    "\n",
    "# print the result\n",
    "# print(labeled_poi_data.head())\n",
    "\n",
    "# updated list\n",
    "updated_list = []\n",
    "\n",
    "# convert the column of lists to a list of lists\n",
    "list_of_lists_poi_id = labeled_poi_data['poi_ids'].tolist()\n",
    "\n",
    "# poi format poi_id = class:numofFacilities\n",
    "# seperate numofFacilities from list_of_lists_poi_id and sum them up\n",
    "\n",
    "# for each list in list_of_lists_poi_id \n",
    "# change the list of poi_id to sum of numofFacilities \n",
    "for poi_list in list_of_lists_poi_id:\n",
    "    weighted_sum = 0\n",
    "    for poi in poi_list:\n",
    "        if(pd.isna(poi)==False):\n",
    "            poi_id, num_of_facilities = poi.split(':')\n",
    "            poi_class = poi_id.split('#')\n",
    "            # combine the class1 and class2 numbers\n",
    "            if(len(poi_class) == 1):\n",
    "                poi_class[0] = '0' + poi_class[0]\n",
    "            else:\n",
    "                poi_number = poi_class[0] + '' + poi_class[1]\n",
    "            weighted_sum += int(num_of_facilities) * int(poi_number)\n",
    "\n",
    "    updated_list.append(weighted_sum)\n",
    "\n",
    "# print(list_of_lists_poi_id)\n",
    "\n",
    "# change labeled_poi_data['poi_ids'] to list_of_lists_poi_id\n",
    "labeled_poi_data['poi_ids'] = updated_list\n",
    "\n",
    "print('labeled_poi_data.head(): ', labeled_poi_data.head())\n",
    "\n",
    "labeled_poi_data.to_csv('../dataset/labeledTestSet/poi_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from the labeled data\n",
    "cluster_map = pd.read_csv('../dataset/labeledTestSet/cluster_map.csv')\n",
    "orders_data = pd.read_csv('../dataset/labeledTestSet/orders_data.csv')\n",
    "weather_data = pd.read_csv('../dataset/labeledTestSet/weather_data.csv')\n",
    "poi_data = pd.read_csv('../dataset/labeledTestSet/poi_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           order_id                         driver_id  \\\n",
      "0  a903b5f7f65f1dc7f4ee94fec74673be  dce1e90fc91ed39a7b04a22d02910a7d   \n",
      "1  b7c838beaf12a2132776a1f00e016038  1f39eba5ce330f20c95177826a122e12   \n",
      "2  0e0d3c93298ed59281352e34c6f1ec5a  8e4e2bc0342b3c55edea2723f6613e36   \n",
      "3  1f6d0d7f68f216c4333969d6152a0a8b  5a33393e516673c8e9a065915667a30f   \n",
      "4  bcf6050d9f5b270f8beb3ff80b01b435  f0232b8e45abc5ca92ca0f90fa811e7c   \n",
      "\n",
      "                  start_region_hash                  dest_region_hash  \\\n",
      "0  d4ec2125aff74eded207d2d915ef682f  d4ec2125aff74eded207d2d915ef682f   \n",
      "1  2407d482f0ffa22a947068f2551fe62c  2407d482f0ffa22a947068f2551fe62c   \n",
      "2  b26a240205c852804ff8758628c0a86a  3a43dcdff3c0b66b1acb1644ff055f9d   \n",
      "3  4725c39a5e5f4c188d382da3910b3f3f  4725c39a5e5f4c188d382da3910b3f3f   \n",
      "4  dd8d3b9665536d6e05b29c2648c0e69a  a5609739c6b5c2719a3752327c5e33a7   \n",
      "\n",
      "   time_slot  weekday  \n",
      "0         44        5  \n",
      "1         78        5  \n",
      "2         92        5  \n",
      "3        102        5  \n",
      "4        114        5  \n",
      "   weather  temperature  pm25  time_slot  weekday\n",
      "0        4          1.0    94         42        5\n",
      "1        3         -1.0   107         67        5\n",
      "2        3         -1.0    56         79        5\n",
      "3        3          0.0    48         90        5\n",
      "4        3          0.0    48         91        5\n"
     ]
    }
   ],
   "source": [
    "# map time to time slot\n",
    "# devide day in 10 min time slots (144 time slots)\n",
    "\n",
    "\n",
    "# convert time to datetime\n",
    "orders_data['time'] = pd.to_datetime(orders_data['time'])\n",
    "weather_data['time'] = pd.to_datetime(weather_data['time'])\n",
    "\n",
    "# map time to time slot\n",
    "orders_data['time_slot'] = orders_data['time'].dt.hour * 6 + orders_data['time'].dt.minute // 10\n",
    "weather_data['time_slot'] = weather_data['time'].dt.hour * 6 + weather_data['time'].dt.minute // 10\n",
    "\n",
    "# map time to time slot with weekday\n",
    "orders_data['weekday'] = orders_data['time'].dt.weekday\n",
    "weather_data['weekday'] = weather_data['time'].dt.weekday\n",
    "\n",
    "# remove the time column\n",
    "orders_data = orders_data.drop(['time'], axis=1)\n",
    "weather_data = weather_data.drop(['time'], axis=1)\n",
    "\n",
    "print(orders_data.head())\n",
    "print(weather_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      start_region_hash                  dest_region_hash  \\\n",
      "0      08232402614a9b48895cc3d0aeb0e9f2  08232402614a9b48895cc3d0aeb0e9f2   \n",
      "1      08232402614a9b48895cc3d0aeb0e9f2  08232402614a9b48895cc3d0aeb0e9f2   \n",
      "2      08232402614a9b48895cc3d0aeb0e9f2  08232402614a9b48895cc3d0aeb0e9f2   \n",
      "3      08232402614a9b48895cc3d0aeb0e9f2  08232402614a9b48895cc3d0aeb0e9f2   \n",
      "4      08232402614a9b48895cc3d0aeb0e9f2  08232402614a9b48895cc3d0aeb0e9f2   \n",
      "...                                 ...                               ...   \n",
      "74066  fff4e8465d1e12621bc361276b6217cf  fff4e8465d1e12621bc361276b6217cf   \n",
      "74067  fff4e8465d1e12621bc361276b6217cf  fff4e8465d1e12621bc361276b6217cf   \n",
      "74068  fff4e8465d1e12621bc361276b6217cf  fff4e8465d1e12621bc361276b6217cf   \n",
      "74069  fff4e8465d1e12621bc361276b6217cf  fff4e8465d1e12621bc361276b6217cf   \n",
      "74070  fff4e8465d1e12621bc361276b6217cf  fff4e8465d1e12621bc361276b6217cf   \n",
      "\n",
      "       time_slot  weekday  supply  \n",
      "0             55        6       1  \n",
      "1             56        2       1  \n",
      "2             56        6       4  \n",
      "3             66        4       2  \n",
      "4             66        5       1  \n",
      "...          ...      ...     ...  \n",
      "74066        126        6       1  \n",
      "74067        127        4       1  \n",
      "74068        128        4       1  \n",
      "74069        139        5       1  \n",
      "74070        140        0       2  \n",
      "\n",
      "[74071 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# group the orders data by time slot \n",
    "# aggregate count the number of orders where driver_id = NULL\n",
    "# this is supply demand deficit\n",
    "\n",
    "orders_data_grouped = orders_data.groupby(['start_region_hash', 'dest_region_hash','time_slot', 'weekday' ]).agg({'order_id': 'count'}).rename(columns={'order_id': 'supply'}).reset_index()\n",
    "\n",
    "print(orders_data_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    time_slot  temperature       pm25\n",
      "0          42     2.000000  81.333333\n",
      "1          43     2.500000  75.000000\n",
      "2          44     2.500000  75.000000\n",
      "3          54     6.000000  30.000000\n",
      "4          55     0.000000  65.000000\n",
      "5          56     3.000000  73.000000\n",
      "6          66     3.500000  74.500000\n",
      "7          67     3.000000  71.250000\n",
      "8          68     1.500000  61.000000\n",
      "9          78     3.500000  63.250000\n",
      "10         79     2.000000  66.500000\n",
      "11         80     3.500000  63.250000\n",
      "12         90     3.250000  50.250000\n",
      "13         91     3.000000  52.333333\n",
      "14         92     4.000000  65.500000\n",
      "15        102     4.000000  58.333333\n",
      "16        103     1.666667  78.333333\n",
      "17        104     3.666667  58.333333\n",
      "18        114     2.500000  74.000000\n",
      "19        115     2.000000  66.000000\n",
      "20        116     2.000000  62.000000\n",
      "21        126     1.333333  84.333333\n",
      "22        127     0.800000  70.000000\n",
      "23        128     2.000000  74.750000\n",
      "24        138     0.800000  73.800000\n",
      "25        139     0.800000  73.800000\n",
      "26        140     0.800000  73.800000\n"
     ]
    }
   ],
   "source": [
    "# group the weather data by time slot\n",
    "# aggregate the mean of temperature and pm25\n",
    "weather_data_grouped = weather_data.groupby(['time_slot']).agg({'temperature': 'mean', 'pm25': 'mean'}).reset_index()\n",
    "\n",
    "print(weather_data_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      start_region_hash                  dest_region_hash  \\\n",
      "0      08232402614a9b48895cc3d0aeb0e9f2  08232402614a9b48895cc3d0aeb0e9f2   \n",
      "1      08232402614a9b48895cc3d0aeb0e9f2  3e12208dd0be281c92a6ab57d9a6fb32   \n",
      "2      08232402614a9b48895cc3d0aeb0e9f2  52d7b69796362a8ed1691a6cc02ddde4   \n",
      "3      08232402614a9b48895cc3d0aeb0e9f2  905ac1f4c0f46a8d31ac4dc68cef54ca   \n",
      "4      08232402614a9b48895cc3d0aeb0e9f2  cb6041cc08444746caf6039d8b9e43cb   \n",
      "...                                 ...                               ...   \n",
      "74066  fff4e8465d1e12621bc361276b6217cf  87285a66236346350541b8815c5fae94   \n",
      "74067  fff4e8465d1e12621bc361276b6217cf  87285a66236346350541b8815c5fae94   \n",
      "74068  fff4e8465d1e12621bc361276b6217cf  fc34648599753c9e74ab238e9a4a07ad   \n",
      "74069  fff4e8465d1e12621bc361276b6217cf  fc34648599753c9e74ab238e9a4a07ad   \n",
      "74070  fff4e8465d1e12621bc361276b6217cf  fff4e8465d1e12621bc361276b6217cf   \n",
      "\n",
      "       time_slot  weekday  supply  temperature       pm25  \n",
      "0             55        6       1          0.0  65.000000  \n",
      "1             55        2       1          0.0  65.000000  \n",
      "2             55        0       1          0.0  65.000000  \n",
      "3             55        6       2          0.0  65.000000  \n",
      "4             55        0       1          0.0  65.000000  \n",
      "...          ...      ...     ...          ...        ...  \n",
      "74066         42        5       1          2.0  81.333333  \n",
      "74067         42        6       1          2.0  81.333333  \n",
      "74068         42        2       1          2.0  81.333333  \n",
      "74069         42        6       2          2.0  81.333333  \n",
      "74070         42        5       1          2.0  81.333333  \n",
      "\n",
      "[74071 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# merge the orders data and weather data\n",
    "orders_weather_data = pd.merge(orders_data_grouped, weather_data_grouped, on='time_slot', how='inner')\n",
    "\n",
    "print(orders_weather_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        region_hash  region_id\n",
      "0  90c5a34f06ac86aee0fd70e2adce7d8a          1\n",
      "1  f2c8c4bb99e6377d21de71275afd6cd2          2\n",
      "2  58c7a4888306d8ff3a641d1c0feccbe3          3\n",
      "3  b26a240205c852804ff8758628c0a86a          4\n",
      "4  4b9e4cf2fbdc8281b8a1f9f12b80ce4d          5\n",
      "                        region_hash    poi_ids\n",
      "0  74c1c25f4b283fa74a5514307b0d0278  192205092\n",
      "1  08f5b445ec6b29deba62e6fd8b0325a6   11664654\n",
      "2  4b7f6f4e2bf237b6cc58f57142bea5c0   26846101\n",
      "3  a814069db8d32f0fa6e188f41059c6e1   21808997\n",
      "4  8316146a6f78cc6d9f113f0390859417    6828078\n",
      "                        region_hash  region_id    poi_ids\n",
      "0  90c5a34f06ac86aee0fd70e2adce7d8a          1  118257404\n",
      "1  f2c8c4bb99e6377d21de71275afd6cd2          2   68155035\n",
      "2  58c7a4888306d8ff3a641d1c0feccbe3          3    5013449\n",
      "3  b26a240205c852804ff8758628c0a86a          4   42874231\n",
      "4  4b9e4cf2fbdc8281b8a1f9f12b80ce4d          5    4327122\n"
     ]
    }
   ],
   "source": [
    "# merge the poi_list class characteristics with the cluster_map\n",
    "# cluster_map: region_hash, region_id\n",
    "# poi_data: district_hash, poi_ids\n",
    "# merge on district_hash\n",
    "cluster_map_poi = pd.merge(cluster_map, poi_data, left_on='region_hash', right_on='region_hash', how='inner')\n",
    "\n",
    "# remove the region_hash column\n",
    "# cluster_map_poi = cluster_map_poi.drop(['region_id'], axis=1)\n",
    "\n",
    "print(cluster_map_poi.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       time_slot  weekday  supply  temperature       pm25  start_region_id  \\\n",
      "0             55        6       1          0.0  65.000000               50   \n",
      "1             56        2       1          3.0  73.000000               50   \n",
      "2             56        6       4          3.0  73.000000               50   \n",
      "3             66        4       2          3.5  74.500000               50   \n",
      "4             66        5       1          3.5  74.500000               50   \n",
      "...          ...      ...     ...          ...        ...              ...   \n",
      "30918         92        5       1          4.0  65.500000               53   \n",
      "30919        128        2       1          2.0  74.750000               53   \n",
      "30920         91        5       1          3.0  52.333333               53   \n",
      "30921         68        2       1          1.5  61.000000               53   \n",
      "30922        138        0       1          0.8  73.800000               53   \n",
      "\n",
      "       start_poi_ids  dest_region_id  dest_poi_ids  \n",
      "0            8576971              50       8576971  \n",
      "1            8576971              50       8576971  \n",
      "2            8576971              50       8576971  \n",
      "3            8576971              50       8576971  \n",
      "4            8576971              50       8576971  \n",
      "...              ...             ...           ...  \n",
      "30918        8554146              55       1880282  \n",
      "30919        8554146              55       1880282  \n",
      "30920        8554146              55       1880282  \n",
      "30921        8554146              55       1880282  \n",
      "30922        8554146              55       1880282  \n",
      "\n",
      "[30923 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# merge the orders_data with the cluster_map_poi\n",
    "# orders_weather_data: start_district_hash, time_slot, weekday, order_gap, temperature, pm25\n",
    "# cluster_map_poi: region_id, poi_ids\n",
    "# merge on start_district_hash\n",
    "# print(orders_weather_data.head())\n",
    "# print(cluster_map_poi.head())\n",
    "\n",
    "orders_weather_cluster_map_poi = pd.merge(orders_weather_data, cluster_map_poi, left_on='start_region_hash', right_on='region_hash', how='inner')\n",
    "orders_weather_cluster_map_poi=orders_weather_cluster_map_poi.rename(columns={'poi_ids': 'start_poi_ids'}).rename(columns={'region_id': 'start_region_id'})\n",
    "\n",
    "orders_weather_cluster_map_poi = pd.merge(orders_weather_cluster_map_poi, cluster_map_poi, left_on='dest_region_hash', right_on='region_hash', how='inner')\n",
    "orders_weather_cluster_map_poi=orders_weather_cluster_map_poi.rename(columns={'poi_ids': 'dest_poi_ids'}).rename(columns={'region_id': 'dest_region_id'})\n",
    "\n",
    "# remove the start_district_hash column\n",
    "orders_weather_cluster_map_poi = orders_weather_cluster_map_poi.drop(['start_region_hash', 'dest_region_hash', 'region_hash_x', 'region_hash_y'], axis=1)\n",
    "\n",
    "print(orders_weather_cluster_map_poi)\n",
    "\n",
    "\n",
    "# save the data\n",
    "orders_weather_cluster_map_poi.to_csv('../dataset/processedData/orders_weather_cluster_map_poi_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
