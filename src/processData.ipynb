{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_map.head(): \n",
      "         90c5a34f06ac86aee0fd70e2adce7d8a    1\n",
      "0  f2c8c4bb99e6377d21de71275afd6cd2    2  NaN\n",
      "1       58c7a4888306d8ff3a641d1c0feccbe3  3.0\n",
      "2       b26a240205c852804ff8758628c0a86a  4.0\n",
      "3       4b9e4cf2fbdc8281b8a1f9f12b80ce4d  5.0\n",
      "4       1cbfbdd079ef93e74405c53fcfff8567  6.0\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-01\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-02\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-03\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-04\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-05\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-06\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-07\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-08\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-09\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-10\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-11\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-12\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-13\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-14\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-15\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-16\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-17\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-18\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-19\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-20\n",
      "filename:  ../dataset/training_data/order_data\\order_data_2016-01-21\n",
      "poi_data.head(): \n",
      "    74c1c25f4b283fa74a5514307b0d0278 1#11:2241 1#10:249   24:1245   25:3652  \\\n",
      "0  08f5b445ec6b29deba62e6fd8b0325a6  20#7:249  20#5:83   2#7:166  20#2:747   \n",
      "1  4b7f6f4e2bf237b6cc58f57142bea5c0  4#16:249   24:913    25:332   20:4316   \n",
      "2  a814069db8d32f0fa6e188f41059c6e1  1#11:498   24:332    25:581   20:5810   \n",
      "3  8316146a6f78cc6d9f113f0390859417  20#7:581  20#5:83  20#4:415  20#2:166   \n",
      "4  693a21b16653871bbd455403da5412b4  1#11:249   25:415   20:2905    22:415   \n",
      "\n",
      "   20:33449     22:2324      23:913    4:13031     8:166  ... 24#1:133713  \\\n",
      "0  20#1:996  16#12:1245  16#10:2158  16#11:415  20#8:249  ...         NaN   \n",
      "1    22:415      4:2158      5#4:83    5#3:166   5#1:332  ...         NaN   \n",
      "2   22:2407      4:1494        8:83    5#1:581   8#2:996  ...         NaN   \n",
      "3  20#1:664   16#12:332   16#10:747  16#11:498  20#8:913  ...         NaN   \n",
      "4     4:498      5#3:83     8#2:581    8#3:166   8#4:830  ...         NaN   \n",
      "\n",
      "  13#4:19173 2#8:166 2#4:249 2#5:1079 2#6:1245 2#7:1826 2#1:83 2#2:9213  \\\n",
      "0        NaN     NaN     NaN      NaN      NaN      NaN    NaN      NaN   \n",
      "1        NaN     NaN     NaN      NaN      NaN      NaN    NaN      NaN   \n",
      "2        NaN     NaN     NaN      NaN      NaN      NaN    NaN      NaN   \n",
      "3        NaN     NaN     NaN      NaN      NaN      NaN    NaN      NaN   \n",
      "4        NaN     NaN     NaN      NaN      NaN      NaN    NaN      NaN   \n",
      "\n",
      "  2#3:415  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n",
      "\n",
      "[5 rows x 139 columns]\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-01\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-02\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-03\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-04\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-05\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-06\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-07\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-08\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-09\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-10\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-11\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-12\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-13\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-14\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-15\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-16\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-17\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-18\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-19\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-20\n",
      "filename:  ../dataset/training_data/weather_data\\weather_data_2016-01-21\n"
     ]
    }
   ],
   "source": [
    "# to clean and pre-process the data\n",
    "# import data using pandas\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the data\n",
    "cluster_map = pd.read_csv('../dataset/training_data/cluster_map/cluster_map', sep='\\t', encoding='utf-8')\n",
    "print('cluster_map.head(): \\n', cluster_map.head())\n",
    "\n",
    "orders_data = []\n",
    "for f in glob.glob('../dataset/training_data/order_data/order_data_*'):\n",
    "    # file name\n",
    "    print('filename: ', f)\n",
    "    # df = pd.read_csv(f, sep='\\t', , on_bad_lines='skip')\n",
    "    # orders_data.append(df)\n",
    "\n",
    "\n",
    "poi_data = pd.read_csv('../dataset/training_data/poi_data/poi_data', sep='\\t', encoding='utf-8', on_bad_lines='skip')\n",
    "print('poi_data.head(): \\n', poi_data.head())\n",
    "\n",
    "weather_data = []\n",
    "for f in glob.glob('../dataset/training_data/weather_data/weather_data_*'):\n",
    "    # file name\n",
    "    print('filename: ', f)\n",
    "    # df = pd.read_csv(f, sep='\\t', encoding='utf-8', on_bad_lines='skip')\n",
    "    # weather_data.append(df)\n",
    "\n",
    "# label the data\n",
    "# label the orders data\n",
    "# orders_data = pd.concat(orders_data)\n",
    "# orders_data['label'] = orders_data['driver_id'].map(cluster_map.set_index('driver_id')['cluster'])\n",
    "# print('orders_data.head(): ', orders_data.head())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
